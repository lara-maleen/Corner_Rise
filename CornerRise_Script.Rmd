---
title: "CornerRise_Script"
author: "Lara Beckmann"
date: "2025-06-18"
always_allow_html: true
output:
  html_document: 
    toc: true
    number_sections: true
    toc_float: true
  word_document: default
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
    latex_engine: xelatex
---

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

# PREPARATIONS

## Set working directory 
> Should include all data files:

* expanded_data_CR.csv
* wide_data_CR.csv
* taxa_sheet_all_CR.csv
* forest_data_CR.csv - also comes with all density files separately

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = '/Users/lara/Downloads/Corner Rise Video Analysis/raw_data')
knitr::opts_chunk$set(echo = TRUE, error = TRUE, message = TRUE, warning = TRUE)

```

```{r, echo=FALSE, message=FALSE}
# Clear the entire environment
rm(list = ls())
```

## Load libraries

```{r, echo=TRUE, message=FALSE}

library(dplyr)
library(tibble)
library(tidyr)
library(GGally) 
library(corrplot)
library(vegan)
library(pvclust)
library(mgcv)
library(knitr)
library(kableExtra)
library(viridis)
library(ggpubr)
library(rcompanion)
library(vegan)
library(cluster)
library(readxl)
library(geosphere)
library(dendextend)
library(ggrepel)
library(FactoMineR)
library(factoextra)
library(purrr)
library(stringr)
library(ggforce)
library(ggridges)
library(forcats)
library(indicspecies)
library(betapart)
library(plotly)
library(htmltools)
library(lubridate)
#remotes::install_github("MikkoVihtakari/ggOceanMaps")
library(ggOceanMaps)

```

## Load all data

```{r}

#expanded data - DATASET A
data.a <- read.csv("./expanded_data_CR.csv", sep = ",", header=TRUE) #extracted from raw data where counts are translated into rows - This is also called Dataset A 

# wide data - DATASET B 
data.b <- read.csv("./wide_data_CR.csv", sep = ",", header=TRUE) #this file is wide data plus all the env data that I extracted manually - This is also called Dataset B, and will become dataset C when aggregated by site

#Load taxa sheet file - TAXA 
taxa <- read.csv("./taxa_sheet_all_CR.csv", sep = ",", header=TRUE) #all morphotypes and their metadata 

#Load the forest data 
garden_length_df <- read.csv("./forest_data_CR.csv", sep = ",", header=TRUE) 

```


# BASIC DATA

> Before starting any data manipulation, getting some data summaries and basic statistics 

## Dive tracks and distances

```{r}


jump_threshold <- 100  # max allowed segment in meters
smoothing_spar <- 0.7

# Process data: smoothing, segment distances, split by jumps. This also account for the 3D distance, so it takes vertical/depth distance into account!

process_dive <- function(dive_df) {
  dive_df <- dive_df %>%
    filter(!is.na(time), !is.na(lat), !is.na(lon), !is.na(depth)) %>%
    arrange(time) %>%
    mutate(
      time = as.POSIXct(time, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
      time_sec = as.numeric(difftime(time, min(time), units = "secs")),
      lat_smooth = predict(smooth.spline(time_sec, lat, spar = smoothing_spar), time_sec)$y,
      lon_smooth = predict(smooth.spline(time_sec, lon, spar = smoothing_spar), time_sec)$y
    ) %>%
    mutate(
      segment_distance_horizontal = c(0, distHaversine(
        cbind(lon_smooth[-n()], lat_smooth[-n()]),
        cbind(lon_smooth[-1], lat_smooth[-1])
      )),
      segment_distance_vertical = c(0, abs(depth[-1] - depth[-n()])), #remove this if you dont want 3D! This uses the Pythagoras function, to get the distance.
      segment_distance_m = sqrt(segment_distance_horizontal^2 + segment_distance_vertical^2),  #remove this if you dont want 3D!
      track_segment = cumsum(c(FALSE, segment_distance_m[-1] > jump_threshold)) + 1 
    ) %>%
    group_by(track_segment) %>%
    mutate(cum_distance_m = cumsum(segment_distance_m)) %>%
    ungroup()
}


# Apply to all dives

data.segmented <- data.a %>%
  split(.$dive_name) %>%
  lapply(process_dive) %>%
  bind_rows()

summary_table <- data.segmented %>%
  group_by(dive_name) %>%
  summarise(
    total_track_length_m = sum(segment_distance_m, na.rm = TRUE),  # this excludes jumps
    min_depth = min(depth, na.rm = TRUE),
    max_depth = max(depth, na.rm = TRUE),
    mean_depth = mean(depth, na.rm = TRUE),
    n_points = n(),
    n_segments = n_distinct(track_segment)
  )

jump_distances <- data.segmented %>%
  group_by(dive_name) %>%
  arrange(time) %>%
  summarise(
    jump_dist_m = sum(
      distHaversine(
        cbind(lon_smooth[-n()], lat_smooth[-n()]),
        cbind(lon_smooth[-1], lat_smooth[-1])
      ) * (track_segment[-1] != track_segment[-n()])
      , na.rm=TRUE)
  )

corrected_summary <- summary_table %>%
  left_join(jump_distances, by = "dive_name") %>%
  mutate(
    jump_dist_m = ifelse(is.na(jump_dist_m), 0, jump_dist_m),
    total_track_length_no_jumps = total_track_length_m - jump_dist_m
  )

corrected_summary

# Depth profile plot

ggplot(data.segmented, aes(cum_distance_m, depth, group = interaction(dive_name, track_segment), color = dive_name)) +
  geom_line() + scale_y_reverse() + theme_minimal() +
  labs(title = "Depth Profile Along Track", x = "Cumulative Distance (m)", y = "Depth (m)")


# 3D plot with segments 

plot_list <- list()

for (dive_name in unique(data.segmented$dive_name)) {
  dive_df <- filter(data.segmented, dive_name == !!dive_name)
  p <- plot_ly()
  
  # Original track
  p <- p %>% add_trace(
    data = dive_df, x = ~lon, y = ~lat, z = ~depth,
    type = 'scatter3d', mode = 'lines',
    line = list(color = 'rgba(100,255,255,0.4)', width = 1),
    name = 'Original'
  )
  
  # Each cleaned segment
  for (seg_id in unique(dive_df$track_segment)) {
    seg_df <- filter(dive_df, track_segment == seg_id)
    p <- p %>% add_trace(
      data = seg_df,
      x = ~lon_smooth, y = ~lat_smooth, z = ~depth,
      type = 'scatter3d', mode = 'lines',
      line = list(width = 7, color = seg_df$depth, colorscale = 'Viridis'),
      hoverinfo = 'text',
      text = ~paste("Depth:", round(depth,1), "m<br>Dist:", round(cum_distance_m), "m"),
      showlegend = FALSE
    )
  }
  
  p <- p %>%
    layout(
      title = list(text = paste("3D Track (Dive", dive_name, ")"), font = list(color = "white")),
      scene = list(
        xaxis = list(title = "Longitude", titlefont=list(color="white"), tickfont=list(color="white")),
        yaxis = list(title = "Latitude", titlefont=list(color="white"), tickfont=list(color="white")),
        zaxis = list(title = "Depth (m)", titlefont=list(color="white"), tickfont=list(color="white"), autorange = "reversed"),
        bgcolor = "#000000"
      ),
      paper_bgcolor = '#000000', plot_bgcolor = '#000000'
    )
  
  plot_list[[dive_name]] <- p
}

# Output all plots together in the markdown
tagList(plot_list)


```


## Summary statistics - morphotype data

> Here I calculate the basics, like how many taxa, how many observations etc. This uses the full expanded dataset (Dataset A) and the taxa sheet. 

```{r}
#How many total morphotypes?
nrow(taxa)
#How many total coral morphotypes?
sum(taxa$Phylum == "Cnidaria")
#How many total sponge morphotypes?
sum(taxa$Phylum == "Porifera")
#How many total observations?
nrow(data.a) #counting all rows of the Dataset A
#How many coral observations?
sum(data.a$Phylum == "Cnidaria")
#How many sponge observations?
sum(data.a$Phylum == "Porifera")
#How many coral observations of species level?
sum(data.a$Phylum == "Cnidaria" & data.a$Species != "")
#How many sponge observations of species level?
sum(data.a$Phylum == "Porifera" & data.a$Species != "")

#How many (and which) morphotypes occurred in a single dive only?
# First, aggregate the data to count the occurrences of each morphotype across all dives
morphotype_counts <- data.a %>%
  group_by(Morphotype) %>%
  summarise(count = n_distinct(dive_name))
# Filter the aggregated data to include only morphotypes that occurred in a single dive
morphotypes_single_dive <- morphotype_counts %>%
  filter(count == 1) #change number for what to check

# count the number of morphotypes that occurred in a single dive
num_single_dive_morphotypes <- nrow(morphotypes_single_dive)
# Print the number of morphotypes that occurred in a single dive
print(num_single_dive_morphotypes)
# Frequency of this number:
(100/(length(unique(data.a$Morphotype))))*num_single_dive_morphotypes
# Can print the morphotypes that occurred in a single dive only: 
#knitr::kable(morphotypes_single_dive, caption = "Morphotypes that occures in a single dive location only")

``` 
## Effort correction 

> Now I want to plot density (number of counts) by depth and divided for each phylum. Since some depths have been visited several times, I am scaling the counts by the length (in meters) of each dive (from transect duration/length above), which results in an effort-corrected count. This way there is no bias on the density, e.g. if more time spent in 1000 m because there were 2 dives. The plot also gives an overview of the highest abundances, and how the abundances change over depth. 

```{r}

### Effort correct based in transect lengths! Different sampling efforts, so need to acount for that (or at least check) Transect length instead of time, as it might be biased by time spend somewhere like a zoom or going up column again ....

# count occurrences per depth and Phylum
df_summary <- data.a %>%
  group_by(depth, Phylum, dive_name) %>%
  summarise(count = n(), .groups = "drop")

# Merge dive track length with df_summary
df_corrected <- df_summary %>%
  left_join(corrected_summary, by = "dive_name") %>% 
  mutate(transect_m = as.numeric(total_track_length_no_jumps), #thats in meters, accounts for the off=bottom time
         Effort_Corrected_count = count / transect_m) # Normalize counts by meter spend during time 

# Plot density with effort correction
ggplot(df_corrected, aes(x = depth, fill = Phylum, weight = Effort_Corrected_count)) +
  geom_density(alpha = 0.7) +  # Density plot with transparency
  scale_fill_manual(values = c("Cnidaria" = "#d8514e", "Porifera" = "#f2c714")) +  # Custom colors
  scale_x_reverse(breaks=seq(800, 5000, 200)) +  # Flip depth axis so shallowest is on top
  coord_flip() +
  labs(x = "depth (m)", y = "Effort-Corrected Density", fill = "Phylum") +
  theme_minimal()

#for paper
# Plot density with effort correction
ggplot(df_corrected, aes(x = depth, fill = Phylum, weight = Effort_Corrected_count)) +
  geom_density(alpha = 0.7) +  # Density plot with transparency
  scale_fill_manual(values = c("Cnidaria" = "#d8514e", "Porifera" = "#f2c714")) +  # Custom colors
  labs(x = "depth (m)", y = "Effort-Corrected Density", fill = "Phylum") +
  theme_minimal()

#plot without effort correction
ggplot(data.a, aes(x = depth, fill = Phylum)) +
  geom_density(alpha = 0.7) + # Adjust transparency
  scale_fill_manual(values = c("Cnidaria" = "#d8514e", "Porifera" = "#f2c714")) +
  labs(x = "depth (m)", y = "Density", fill = "Phylum") +
  theme_minimal() +
  coord_flip() +
  scale_x_reverse(breaks=seq(800, 5000, 200)) 

# Bin the df into depth for a test on the abundances by depth - bins in 5 meter, but can be adapted. 

df_corrected <- df_corrected %>%
  mutate(depth_bin = cut(depth, breaks = seq(0, max(depth), by = 5), include.lowest = TRUE)) %>%
  mutate(depth_bin = as.factor(depth_bin))  

# Is there a linear effect? 
glm_model <- glm(Effort_Corrected_count ~ depth, data = df_corrected, family = quasipoisson) # need to use quasipoisson because its non-integer counts with the correction 
summary(glm_model) # No
glm_numeric <- glm(Effort_Corrected_count ~ as.numeric(depth),  data = df_corrected, family = quasipoisson)
summary(glm_numeric) # No

# Is there a non-linear effect?
gam_model <- gam(Effort_Corrected_count ~ s(depth), data = df_corrected, family = quasipoisson) 
summary(gam_model) # yes, significant, meaning that there are peaks with higher abundances, but no linear decline. 
plot(gam_model) 

# Is there an overall depth effect?
anova(glm_model, test = "Chisq") # no 

# And if we use the non-corrected data? 
glm_model <- glm(count ~ depth, data = df_summary, family = poisson)
summary(glm_model)  # Poisson - this is significant, but might be biased because of the sampling effort
     
```

> In geom_density(), the density represents a smoothed estimate of the distribution of observations across depth.
It's similar to a histogram but smoothed into a continuous curve. 
The uncorrected plot could over-represent depths where more time was spent during each dive, also overlapping dives.
The effort-corrected plot gives a better idea of relative abundance per unit effort, making it more comparable across depths.

> The statistical tests on depth effect on abundances shows a complex situation. But there is not a linear trend, that is abundances are not decreasing with depth, but that there are peaks. From the GAM model there are three large peaks (this could also be because of the sites...), but the middle peak is the lowest. 

> Continuing with morphotypes per depth, as overview of how many morphotyes were seen across the depth. 

```{r}

# count unique morphotypes per depth for each phylum
morpho_diversity <- data.a %>%
  group_by(depth, Phylum) %>% # by each depth now, but can also be done with depth bin, replacing than depth with depth_bin
  summarise(Unique_Morphotypes = n_distinct(Morphotype), .groups = "drop")

df_corrected <- df_summary %>%
  left_join(corrected_summary, by = "dive_name") %>% 
  mutate(transect_m = as.numeric(total_track_length_no_jumps), #thats in meters, accounts for the off=bottom time
         Effort_Corrected_count = count / transect_m) 

# Step 2: Merge with df_corrected (Ensuring Consistency)
df_corrected <- df_corrected %>%
  left_join(morpho_diversity, by = c("depth", "Phylum"))  
 
df_corrected <- df_corrected %>% 
   mutate(Effort_Corrected_Div = Unique_Morphotypes / transect_m) # Normalize counts by meters

ggplot(df_corrected, aes(x = depth, fill = Phylum, weight = Effort_Corrected_count)) +
  #geom_density(alpha = 0.7) +  # Density plot with transparency
  geom_smooth(aes(y = Effort_Corrected_Div, color = Phylum), method = "loess", se = TRUE) +
  scale_fill_manual(values = c("Cnidaria" = "#d8514e", "Porifera" = "#f2c714")) +  # Custom color
  #coord_flip() +
  labs(x = "depth (m)", y = "Effort-Corrected Diversity", fill = "Phylum") +
  theme_minimal() 
  #scale_x_reverse(breaks=seq(800, 5000, 200)) 

```

> Next another density plot / ridgleine plot for representation by dive sites

``` {r}

#Assign clusters - this will be explained later in the script. But can be used here in the plots already ...

cluster_assignments <- data.frame(
  dive_name = c(
    "EX2104_Dive03 Hopscotch Seamount",
    "EX2104_Dive04 Dumbbell Seamount",
    "EX2104_Dive05 Rockaway Seamount",
    "EX2104_Dive06 Castle Rock Seamount",
    "EX2104_Dive07 Corner Rise 1 Seamount",
    "EX2104_Dive08 MacGregor Seamount",
    "EX2104_Dive09 Yakutat Shallow Seamount",
    "EX2104_Dive10 Yakutat Deep Seamount",
    "EX2104_Dive11 Caloosahatchee Seamount"
  ),
  cluster = c("cluster1", "cluster1", "deep", "cluster1", "cluster1", "cluster2", "cluster2", "cluster2", "cluster2"))  # This is based on the upcoming analysis, but I wanted to include it here. 

# Optional: filter just Cnidaria and Porifera
plot_df <- data.a %>%
  filter(Phylum %in% c("Cnidaria", "Porifera"))

# Order locations by mean depth
location_order <- plot_df %>%
  group_by(dive_name) %>%
  summarise(mean_depth = mean(depth, na.rm = TRUE)) %>%
  arrange(mean_depth) %>%
  pull(dive_name)

# Apply order to factor
plot_df$dive_name <- factor(plot_df$dive_name, levels = location_order)

# Merge cluster info
plot_df <- data.a %>%
  filter(Phylum %in% c("Cnidaria", "Porifera")) %>%
  left_join(cluster_assignments, by = c("dive_name" = "dive_name"))

# Order locations by mean depth
location_order <- plot_df %>%
  group_by(dive_name) %>%
  summarise(mean_depth = mean(depth, na.rm = TRUE)) %>%
  arrange(mean_depth) %>%
  pull(dive_name)

plot_df$dive_name <- factor(plot_df$dive_name, levels = location_order)
plot_df$cluster <- factor(plot_df$cluster)  # ensure cluster is a factor

ggplot(plot_df, aes(x = depth, y = dive_name, fill = Phylum)) +
  geom_density_ridges(
    aes(group = interaction(dive_name, Phylum)),
    alpha = 0.6,
    scale = 2,  # Lowered from 3.5 for broader peaks
    rel_min_height = 0.01,
    color = "white",
    size = 0.3
  ) +
  #scale_x_reverse(expand = expansion(mult = c(0.01, 0.05))) +  # More space on x-axis
  scale_fill_manual(values = c("Cnidaria" = "#0072B2", "Porifera" = "#D55E00")) +
  facet_grid(cluster ~ ., scales = "free_y", space = "free_y") +  # Stack by cluster
  labs(
    x = "Depth (m)",
    y = NULL,
    title = "Depth Distributions of Coral and Sponge Annotations by Dive",
    fill = "Phylum"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    strip.text.y = element_text(angle = 0, face = "bold"),
    panel.grid.major.y = element_blank(),
    axis.text.y = element_text(size = 10)
  )

#add morphotype richness

# Calculate morphotype richness per dive and phylum (total across all depths)
richness_summary <- plot_df %>%
  group_by(dive_name, Phylum) %>%
  summarise(morphotype_richness = n_distinct(Morphotype), .groups = "drop")
richness_summary$dive_name <- factor(richness_summary$dive_name, levels = location_order)

# Ridgeline plot of abundance/density (your original plot style)
p <- ggplot(plot_df, aes(x = depth, y = dive_name, fill = Phylum)) +
  geom_density_ridges(
    aes(group = interaction(dive_name, Phylum)),
    alpha = 0.6,
    scale = 2,
    rel_min_height = 0.01,
    color = "white",
    size = 0.3
  ) +
  scale_fill_manual(values = c("Cnidaria" = "#0072B2", "Porifera" = "#D55E00")) +
  #scale_x_reverse(expand = expansion(mult = c(0.01, 0.05))) +
  labs(
    x = "Depth (m)",
    y = NULL,
    title = "Depth Distributions of Coral and Sponge Annotations by Dive",
    fill = "Phylum"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    panel.grid.major.y = element_blank(),
    axis.text.y = element_text(size = 10)
  )

# Add morphotype richness dots - position dots just right of the max depth (e.g., at x=10 m shallower than min depth)
min_depth <- min(plot_df$depth)
richness_summary <- richness_summary %>%
  mutate(xpos = min_depth - 10)  # Place dots left of x-axis range (shallower)

p + 
  geom_point(
    data = richness_summary,
    aes(x = xpos-250, y = dive_name, color = Phylum, size = morphotype_richness, alpha=0.7),
    position = position_nudge(y = ifelse(richness_summary$Phylum == "Cnidaria", 0.20, -0.20)),
    inherit.aes = FALSE
  ) +
  scale_color_manual(values = c("Cnidaria" = "#0072B2", "Porifera" = "#D55E00")) +
  scale_size_continuous(range = c(0.5, 7)) +
  guides(
    size = guide_legend(title = "Morphotype Richness"),
    color = "none"
  )


```


## Summary statistics - environmental data

```{r}

#I need to add dive_name to data.b
data.a <- data.a %>% mutate(time = as.POSIXct(time, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"))
data.b <- data.b %>% mutate(time = as.POSIXct(time, format = "%Y/%m/%d %H:%M:%S", tz = "UTC"))

## Extract metadata for each dive - use dataset B
meta_summary <- data.b %>%
  group_by(dive_name) %>%
  summarise(across(c(lat, lon, oxygen, depth, temp), 
                   list(mean = ~mean(.x, na.rm=TRUE), sd = ~sd(.x, na.rm=TRUE))))

kable(meta_summary) %>%
  kable_styling(font_size = 5, latex_options = c("striped")) 
                
# What are max/min values for depth, oxygen etc?

max(data.a$depth)
min(data.a$depth)
max(data.a$oxygen)
min(data.a$oxygen)

# For Atlantic: Threshold values for OMZ: <2.1 mg/L or hypoxic <0.7 mg/L

omz <- 2.1 # 2.1 is the threshold for mg/L
hypoxic <- 0.7 # 0.7 is the threshold for a severe hypoxic condition in mg/L 

# Which depths are inside the OMZ? 

within_omz <- data.a %>% filter(oxygen < omz)
min(within_omz$depth)
max(within_omz$depth) 

#No values within OMZ range

#Also check medium by all dives:
substrate_percent <- data.a %>%
  group_by(dive_name, medium) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(dive_name) %>%
 mutate(percent = 100 * count / sum(count))

substrate_percent

```

## Correlations - environmental variables

> Check if any of the environmental variables are correlated, this is important for the analysis, and can be used to exclude variables, simplifying the further analysis.

```{r}

# There were some sensor issues at Dive 5 - Rockaway Seamount. PSU and oxygen values do not correspond - and there is a jump in the data. I am keeping the values that do make sense (based on other studies etc)

# Filter realistic salinity values (33–35.2 PSU) and oxygen (7–9 mg/L)
data.clean <- data.a[data.a$psu >= 33 & data.a$psu <= 35.2, ]

# filter oxygen to remove coinciding outliers
data.clean <- data.clean[data.clean$oxygen >= 7 & data.clean$oxygen <= 8.6, ]

min(data.clean$temp, na.rm = TRUE)
max(data.clean$temp, na.rm = TRUE)
data.clean[which.min(data.clean$temp), c("dive_name","depth","temp")]
data.clean[which.max(data.clean$temp), c("dive_name","depth","temp")]

min(data.clean$oxygen, na.rm = TRUE)
max(data.clean$oxygen, na.rm = TRUE)
data.clean[which.min(data.clean$oxygen), c("dive_name","depth","oxygen")]
data.clean[which.max(data.clean$oxygen), c("dive_name","depth","oxygen")]


# Compute Pearson correlation matrix
env.pearson <- cor(data.clean[,5:14], use = "pairwise.complete.obs")
round(env.pearson, 2)

# Pairplot with correlation coefficients
ggpairs(data.clean[,5:14], 
        lower = list(continuous = wrap("smooth", color = "blue")),  # Smoothed regression lines
        upper = list(continuous = wrap("cor", size = 5)),  # Pearson correlation values
        diag = list(continuous = wrap("barDiag", fill = "lightblue"))) +  # Histogram on diagonals
  theme_bw()

# Correlation plot
corrplot(env.pearson, method = "circle", type = "upper", tl.col = "black", tl.cex = 0.8, addCoef.col = "black")

```

### Temperature-Oxygen and Temperature-Salinity Plots

```{r}

# Create the plot 1) TEMP vs Oxgyen
ggplot(data.clean, aes(y = temp, x = oxygen, color = depth)) +
  geom_point(size = 1) +    # Scatter plot with color representing depth
  #scale_color_gradient(name = "depth (m)", low = "blue", high = "red") +  # Color gradient
  scale_color_viridis(option = "viridis", direction = -1) +  # Color scale with cividis for colorblind-friendly option
  #scale_y_reverse() +  # Reverse y-axis to put shallow depth on top
  xlab("Oxygen (mg/L)") +                         # X-axis label
  ylab("Temperature (°C)") +                      # Left y-axis label
  theme_linedraw() +
  theme(panel.grid = element_blank(),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        axis.title.x = element_text (size = 14),
        axis.title.y = element_text(size = 14),
        legend.background = element_blank(),
        legend.box.background= element_rect(colour="black"),
        legend.position = "right")

# Create the plot 2) Salinity vs Temperature
ggplot(data.clean, aes(y = temp, x = psu, color = depth)) +
  geom_point(size = 1) +    # Scatter plot with color representing depth
  #scale_color_gradient(name = "depth (m)", low = "blue", high = "red") +  # Color gradient
  scale_color_viridis(option = "viridis", direction = -1) +  # Color scale with cividis for colorblind-friendly option
  #scale_y_reverse() +  # Reverse y-axis to put shallow depth on top
  xlab("Salinity (psu)") +                         # X-axis label
  ylab("Temperature (°C)") +                      # Left y-axis label
  theme_linedraw() +
  theme(panel.grid = element_blank(),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        axis.title.x = element_text (size = 14),
        axis.title.y = element_text(size = 14),
        legend.background = element_blank(),
        legend.box.background= element_rect(colour="black"),
        legend.position = "right")

```

> Now extract individual columns, this is needed for the next steps

```{r, results='hide'}

#Extract individual df for coordinates, species data and env data
#Also add the substrate from data.a
medium <- data.a %>%
  group_by(time, medium) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(time) %>%
  slice_max(count, n = 1, with_ties = FALSE) %>%
  select(time, medium)

data.b <- data.b %>%
  left_join(medium, by = "time")

coord <- data.frame(
  lat = round(data.b[, 115], 6),
  lon = round(data.b[, 116], 6))
ENV   <-data.b[,115:120] #all the env data
SPE   <-data.b[,3:114] #all annotation/taxa data
#write.xlsx(SPE, "SPE_data.xlsx") #to check the df if needed

```

## Create Dataset C

> In some cases, a dataset is needed where all data is aggregated by site. Here, I will call this Dataset C (short dataset) in contrast to Dataset B (full dataset, rows being annotation timestamps)

```{r}

# Example definition for get_mode() if you don't have one
get_mode <- function(x) {
  ux <- unique(na.omit(x))
  ux[which.max(tabulate(match(x, ux)))]
}

data.c <- data.b %>%
  group_by(dive_name) %>%
  summarise(
    # Sum all SPE columns (make sure they exist in data.b)
    across(all_of(colnames(SPE)), sum, .names = "{.col}"),
    
    # Mode of medium
    medium = get_mode(medium),
    
    # Mean of numeric columns that exist in ENV and data.b
    across(all_of(intersect(colnames(ENV), colnames(data.b))) & where(is.numeric), mean, na.rm = TRUE),
    
    # First of coord columns (make sure they exist)
    across(all_of(colnames(coord)), first, .names = "{.col}"),
    
    .groups = "drop"
  ) %>%
  as.data.frame()

```

> Now I want to create again SPE and ENV dfs from the combined dataset C

```{r}

ENV2<-data.c[,114:119] #all the env data
SPE2<-data.c[,2:113] #all annotation/taxa data
#write.xlsx(SPE2, "SPE_data.xlsx") #to check the df if needed 

```

## Create Dataset FL (Family Level)

> Since there might be patterns in the family instead of morphotypes, the data is aggregated into family level. 
> Note that I have not used this dataset for the Corner Rise analysis, but still migth be useful for further exploration. 

```{r}

# Merge taxa information with the column names of SPE, Define a function to replace NA values with the next available information, and replace empty strings with NA
taxa[taxa == ""] <- NA
fill_family <- function(df) {
  df %>%
    mutate(Family = ifelse(is.na(Family),
                           ifelse(!is.na(Class), Class, Phylum),
                           Family))}

taxa_filled <- fill_family(taxa)
column_names <- data.frame(Morphotype = colnames(SPE), stringsAsFactors = FALSE)
taxa_mapping <- taxa_filled %>%
  dplyr::select(Morphotype, Family) %>%
  dplyr::mutate(Family = as.factor(Family))

# Merge column names with taxa information
column_info <- merge(column_names, taxa_mapping, by = "Morphotype", all.x = TRUE)
# Group columns by family
grouped_columns <- column_info %>%
  group_by(Family) %>%
  summarise(Morphotype = list(Morphotype), .groups = 'drop')

# Initialize a new data frame for combined data
SPE.fam <- data.frame(matrix(ncol = nrow(grouped_columns), nrow = nrow(SPE)))
colnames(SPE.fam) <- grouped_columns$Family

# Combine columns by family
for (i in 1:nrow(grouped_columns)) {
  family_columns <- grouped_columns$Morphotype[[i]]
  # Ensure that the selected columns are treated as a data frame
  selected_data <- SPE[ , family_columns, drop = FALSE]
  # Sum columns belonging to the same family
  SPE.fam[[i]] <- rowSums(selected_data, na.rm = TRUE)
}

# print to check
# SPE.fam

```

## Transform data 

> To continue with the ordination methods, the environmnetal and species data needs to be transformed. This is the case when count data is used, and many zeros are present e.g. Most commonly used are Hellinger transformation for species data, and standardisation for environmental data. This is needed later on. 

```{r, warning=FALSE}

# Morphotype data
# Hellinger transformation

# SPE is the "full" data, so all annotations
SPE.hel <- decostand(SPE, method="hellinger")
plotNormalHistogram(SPE.hel) # checking the distribution

#SPE2 is the aggregated data, grouped by sites
SPE2.hel <- decostand(SPE2, method="hellinger")
plotNormalHistogram(SPE2.hel) # checking the distribution

# Hellinger pre-transformation of the species data 
# Compute square root of relative abundances per site
SPE.hel3 <-decostand(SPE.fam, method="hellinger") # full data, not grouped by site 

# Environmental data
# Standardization

# Convert character to factor, then to numeric
ENV$medium <- as.numeric(as.factor(ENV$medium))
env.z <- decostand(ENV, method="standardize") # After Borcard 

ENV2$medium <- as.numeric(as.factor(ENV2$medium))
env2.z <- decostand(ENV2, method= "standardize") # After Borcard 


```

# DISTRIBUTION PATTERNS

> Here the morphotype data is explored in more detail. Which family most speciose and so on. 

```{r}

# Which is the most abundant morphotype?
# Sum the counts for each morphotype (column) across all locations (rows)
total_abundance <- colSums(SPE)
# Sort the families by total abundance in descending order
most_abundant_taxa <- sort(total_abundance, decreasing = TRUE)
# View the sorted list of most abundant taxa
most_abundant_taxa

# Which is the most abundant family?
# Sum the counts for each morphotype (column) across all locations (rows)
total_abundance_fam <- colSums(SPE.fam)
most_abundant_family<- sort(total_abundance_fam, decreasing = TRUE)
most_abundant_family 

# Which taxa/families are depth generalists? Which are more specialised? (Occuring in only one depth e.g.)

# Combine species data with depth information
species_depth <- cbind(SPE.fam, depth = ENV$depth)

# count how many unique depths each morphotype appears in
species_depth_counts <- species_depth %>%
  summarise(across(-depth, ~length(unique(depth[. > 0])))) %>%
  t() %>%
  as.data.frame()

colnames(species_depth_counts) <- "Unique_depths"
species_depth_counts$Species <- rownames(species_depth_counts)

# View family with the most and least depth occurrences
species_depth_counts <- species_depth_counts[order(species_depth_counts$Unique_depths), ]

# Define threshold (e.g., species in < 10 depths = specialist, otherwise generalist)
species_depth_counts$Category <- ifelse(species_depth_counts$Unique_depths < 10, "Specialist", "Generalist")

# Convert SPE to long format for ggplot
species_long <- SPE.fam %>% #HERE CHANGE TO SPE if you want to check for morphotypes instead
  mutate(depth = ENV$depth) %>%
  pivot_longer(cols = -depth, names_to = "Species", values_to = "Abundance") %>%
  filter(Abundance > 0)  # Remove absences

# Calculate depth range for each species
species_ranges <- species_long %>%
  group_by(Species) %>%
  summarise(Mindepth = min(depth), Maxdepth = max(depth)) %>%
  mutate(depthRange = Maxdepth - Mindepth,
         Category = ifelse(depthRange > 1000, "Generalist", "Specialist"))

# Merge category information with long species data
species_long <- species_long %>%
  left_join(species_ranges, by = "Species")

# Plot with generalists highlighted
ggplot(species_long, aes(x = reorder(Species, depth), y = depth, color = Category)) +
  geom_boxplot() +
  coord_flip() +
  scale_color_manual(values = c("Generalist" = "red", "Specialist" = "black")) + 
  labs(y = "depth (m)", x = "Species",
       title = "Families depth Ranges",
       color = "Category") +
  theme_minimal()

```

# DIVERSITY INDICES

## Alpha Diversity

```{r}

# Shannon's H' (for each dive)
H <- tapply(data.a$Morphotype, data.a$dive_name, function(x) {
  species_abundance <- table(x)
  diversity_index <- diversity(species_abundance, index = "shannon")
  return(diversity_index)
})

# Simpsons (for each dive)
S <- tapply(data.a$Morphotype, data.a$dive_name, function(x) {
  species_abundance <- table(x)
  diversity_index <- diversity(species_abundance, index = "simpson")
  return(diversity_index)
})

# Observed Richness
richness <- tapply(data.a$Morphotype, data.a$dive_name, function(x) {
  species_abundance <- table(x)
  diversity_index <- specnumber(species_abundance)
  return(diversity_index)
})

# Pielou's Evenness
#Evenness is a measure of the relative abundance of the different species in the same area. 
#Low J indicates that 1 or few species dominate the community
evenness <- H/log(richness)

# Create alpha diversity dataframe, include info about environmnent and locations
div.df <- cbind(shannon = H, richness = richness, pielou = evenness, simps = S, ENV2)
div.df$site <-  data.c[,1]

kable(div.df) %>% kable_styling(font_size = 8, latex_options = c("striped"))

# can also sort Locations by the median of 'shannon'
# div.df$site <- with(div.df, reorder(site, shannon, median))

plot.shan <- ggplot(div.df, aes(x = site, y = shannon, colour = depth, shape = as.factor(medium))) + 
  geom_point(size = 3) +
  scale_colour_viridis_c(option = "cividis", begin = 1, end = 0) +
  ylab("Shannon's H") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.4),
        plot.margin = unit(c(0, 0, 0, 0), "cm"))  # Ensure margins are set
#scale_shape_manual(values = c(15, 16, 17, 18, 19, 20, 21, 22, 23))  # Customize the shapes as needed
plot.shan

plot.rich <- ggplot(div.df, aes(x = site, y = richness, colour = depth, shape = as.factor(medium))) + 
  geom_point(size = 3) +
  scale_colour_viridis_c(option = "cividis", begin = 1, end = 0) +
  ylab("Richness") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.4),
        plot.margin = unit(c(0, 0, 0, 0), "cm"))  # Ensure margins are set
#scale_shape_manual(values = c(15, 16, 17, 18, 19, 20, 21, 22, 23))  # Customize the shapes as needed
plot.rich

plot.even <- ggplot(div.df, aes(x = site, y = pielou, colour = depth, shape = as.factor(medium))) + 
  geom_point(size = 3) +
  scale_colour_viridis_c(option = "cividis", begin = 1, end = 0) +
  ylab("Pielous eveness") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.4),
        plot.margin = unit(c(0, 0, 0, 0), "cm"))  # Ensure margins are set
#scale_shape_manual(values = c(15, 16, 17, 18, 19, 20, 21, 22, 23))  # Customize the shapes as needed
plot.even

```
> Now, we explore the alpha diversity further

```{r}

# What impacts have the various environmental factors on the diversity? 

# Define response variables
responses <- c("shannon", "simps", "pielou", "richness")
# Define predictor variables
predictors <- c("depth", "medium", "temp")

# Run linear models and print summaries
lm_results <- lapply(responses, function(resp) {
  cat("\n### Response:", resp, "###\n")
  lapply(predictors, function(pred) {
    cat("\nModel:", resp, "~", pred, "\n")
    print(summary(lm(as.formula(paste(resp, "~", pred)), data = div.df)))
  })})

#Plot with smoothing regression to show trend...
depth.reg <- ggplot(div.df, aes(x = depth, y = shannon, colour = site)) +
  geom_smooth(method = "lm", colour = "black", fill = "grey90") +
  geom_point(size = 3) +
  scale_colour_viridis_d(option = "magma", begin = 0.2, end = 0.8) +
  xlab(bquote(depth (m))) + 
  ylab("Shannon's H'") +
  ylim(0,3.5) +
  theme_bw()
depth.reg 

sediments.reg <- ggplot(div.df, aes(x = medium, y = shannon, colour = site)) +
  geom_point(size = 3) +
  scale_colour_viridis_d(option = "magma", begin = 0.2, end = 0.8) +
  xlab("Primary sediment consistency (m)") + 
  ylab("Shannon's H'") +
  ylim(0,3.5) +
  theme_bw()
sediments.reg 

# Run linear models and print summaries
anova_results <- lapply(responses, function(resp) {
  cat("\n### Response:", resp, "###\n")
  lapply(predictors, function(pred) {
    cat("\nModel:", resp, "~", pred, "\n")
    print(summary(aov(as.formula(paste(resp, "~", pred)), data = div.df)))
  })})

#Explore the medium/substrate - OBS: Only one has predominantly gravel, all others are bedrock ... 
sed.plot <- ggplot(div.df, aes(x = medium, y = shannon, fill = as.factor(medium))) +
  geom_boxplot(aes(fill = as.factor(medium))) +
  geom_point(size = 3, aes(colour = site)) + 
  scale_colour_viridis_d(option = "magma", begin = 0.2, end = 0.8) +
  scale_fill_manual(values = c("grey60", "grey90", "black"), guide = FALSE) +
  ylab("Shannon's H'") + 
  xlab('')+
  theme_bw() 
sed.plot


```

## Beta Diversity


```{r}

# To calculate Beta diversity (across sites) pairwise dissimilarities/distances need to be calculated
# Prepare data: Convert morphotype data to presence-absence matrix
SPE.pa <- table(data.a$dive_name, data.a$Morphotype) #this is an abundance matrix with actual numbers.This is better than using just 0/1 presence/absence because bray curtis is sensitive to abundances. It also adds some more value to the data. 

# Calculate beta diversity using Bray-Curtis dissimilarity
bray.df <- vegdist(SPE.pa, method = "bray") %>%
  as.matrix() %>%
  as.data.frame()

# The matrix can be further used to explore how distant sites are. 
# 1) Are sites more similar that are closer to each other? GEOGRAPHIC DISTANCE

divesites <- unique(data.a$dive_name)
# Create a list to store the first coordinate values and Dive names for each Dive site
first_coordinates_list <- lapply(divesites, function(dive_site) {
  # Extract the first coordinate values for the Dive site
  first_coordinates <- data.a %>%
    filter(dive_name == dive_site) %>%
    slice(1) %>%
    dplyr::select(dive_name, lat, lon)
  return(first_coordinates)
  })

# Extract latitude and longitude values from the list of data frames
coordinates <- lapply(first_coordinates_list, function(df) df[, c("lon", "lat")])
# Convert the list of coordinates to a matrix
coordinates_matrix <- do.call(rbind, coordinates)
# Calculate distances between points using the distm function with Haversine formula (for km)
distance_matrix <- distm(coordinates_matrix)

rownames(distance_matrix) <- data.c$dive_name
colnames(distance_matrix) <- data.c$dive_name

# Print the distance matrix - if wanted
# print(distance_matrix)
heatmap(distance_matrix)
# Convert depth_distance_matrix to long format
geo_long <- as.data.frame(as.table(distance_matrix))
colnames(geo_long) <- c("Site1", "Site2", "Geo")
# Convert bray_curtis_matrix to long format
bray_long <- as.data.frame(as.table(as.matrix(bray.df)))
colnames(bray_long) <- c("Site1", "Site2", "Bray_Curtis")
# Merge the dataframes on Site1 and Site2
combined_df <- merge(geo_long, bray_long, by = c("Site1", "Site2"))
# Remove rows where Site1 == Site2 (comparisons with self)
combined_df <- combined_df[combined_df$Site1 != combined_df$Site2, ]

# 2) Are sites more similar that share similar depths? depth DISTANCE

# Create an empty matrix to store the depth distances
depth_distance_matrix <- matrix(NA, nrow = nrow(data.c), ncol = nrow(data.c)) # using data.c as this has the average depths for each site ready

# Fill the matrix with depth differences
for (i in 1:nrow(data.c)) {
  for (j in 1:nrow(data.c)) {
    # Calculate the absolute difference in depths between locations i and j
    depth_distance_matrix[i, j] <- abs(data.c$depth[i] - data.c$depth[j])
  }}

# Convert matrices to DISTANCE objects (crucial!)
bray_dist <- as.dist(as.matrix(bray.df))          # Bray-Curtis
geo_dist <- as.dist(distance_matrix)              # Geographic
depth_dist <- as.dist(depth_distance_matrix)      # Depth

# Run Mantel tests (9999 permutations for robust p-values)
mantel_geo <- mantel(bray_dist, geo_dist, method = "pearson", permutations = 9999)
mantel_depth <- mantel(bray_dist, depth_dist, method = "pearson", permutations = 9999)

# Print results
print(mantel_geo)
print(mantel_depth)

# Replace nested loops for depth matrix with:
depth_distance_matrix <- as.matrix(dist(data.c$depth, diag = TRUE, upper = TRUE))
# More efficient haversine matrix (replace distm approach):
library(geodist)
geo_matrix <- geodist(coordinates_matrix, measure = "haversine")

# Use this for ALL Mantel plot visualizations (no statistical labels)
plot_mantel <- function(dist_matrix, xlab) {
  df <- data.frame(
    Distance = as.vector(as.dist(dist_matrix)),
    Bray = as.vector(as.dist(as.matrix(bray.df)))
  )
  
  ggplot(df, aes(x = Distance, y = Bray)) +
    geom_point(alpha = 0.6) +
    geom_smooth(method = "lm", color = "red") +
    labs(x = xlab, y = "Bray-Curtis Dissimilarity") +
    theme_minimal()
}

plot_mantel(geo_matrix, "Geographic Distance (m)")
plot_mantel(depth_distance_matrix, "Depth Difference (m)")


```

> Use comm matrix to infer nestedness and turnover between sites

``` {r}

# Replace 'morphotype' with your actual column name for coral/sponge ID
community_matrix <- data.a %>%
  group_by(dive_name, Morphotype) %>%   # Use dive_id or dive_name as grouping var
  summarise(count = n(), .groups = "drop") %>%
  pivot_wider(names_from = Morphotype, values_from = count, values_fill = 0) %>%
  column_to_rownames("dive_name")

# Convert to presence/absence for Jaccard-based analysis
comm_pa <- (community_matrix > 0) * 1

# Run beta diversity partitioning
beta_core <- betapart.core(comm_pa)
beta_results <- beta.multi(beta_core, index.family = "jaccard")
print(beta_results)

beta_pair <- beta.pair(beta_core, index.family = "jaccard")
beta_pair
# For example, visualize turnover:
heatmap(as.matrix(beta_pair$beta.jtu), main = "Turnover between dives")

# Assume comm_pa is your presence-absence community matrix (sites x species)
beta_pair <- beta.pair(comm_pa, index.family = "sor")

turnover_df <- as.data.frame(as.matrix(beta_pair$beta.sim)) %>%
  rownames_to_column("Var1") %>%
  pivot_longer(-Var1, names_to = "Var2", values_to = "value")
nestedness_df <- as.data.frame(as.matrix(beta_pair$beta.sne)) %>%
  rownames_to_column("Var1") %>%
  pivot_longer(-Var1, names_to = "Var2", values_to = "value")

# Combine into one data frame with a label
turnover_df$component <- "Turnover"
nestedness_df$component <- "Nestedness"
beta_long <- rbind(turnover_df, nestedness_df)
colnames(beta_long) <- c("Site1", "Site2", "Dissimilarity", "Component")

# Remove self comparisons (Site1 == Site2)
beta_long <- beta_long[beta_long$Site1 != beta_long$Site2, ]

ggplot(beta_long, aes(x=Component, y=Dissimilarity)) +
  geom_boxplot(fill = c("skyblue", "orange")) +
  labs(title="Pairwise Beta Diversity Components", y="Dissimilarity", x="Component") +
  theme_minimal()

#Make a vector that has the clusters we identified before:
group_vector <- c("cluster1", "cluster1", "deep", "cluster1", "cluster1", 
                  "cluster2", "cluster2", "cluster2", "cluster2")

# Create a data frame with group info for each site
group_df <- data.frame(site = rownames(comm_pa), group = group_vector)

# Function to get turnover values between all pairs and their group combinations
get_pairwise_turnover <- function(beta_matrix, group_df) {
  pairs <- combn(rownames(beta_matrix), 2)
  results <- data.frame(
    site1 = pairs[1,],
    site2 = pairs[2,],
    turnover = mapply(function(x,y) beta_matrix[x,y], pairs[1,], pairs[2,]))
  # Add group info for each site
  results <- merge(results, group_df, by.x = "site1", by.y = "site")
  colnames(results)[4] <- "group1"
  results <- merge(results, group_df, by.x = "site2", by.y = "site")
  colnames(results)[5] <- "group2"
  # Label pairs as within-group or between-group
  results$pair_type <- ifelse(results$group1 == results$group2, "Within group", "Between groups")
  return(results)
}

turnover_pairs <- get_pairwise_turnover(as.matrix(beta_pair$beta.sim), group_df)

# Boxplot turnover by pair type
ggplot(turnover_pairs, aes(x=pair_type, y=turnover, fill=pair_type)) +
  geom_boxplot() +
  labs(title="Species Turnover Within and Between Groups", y="Turnover (β_SIM)", x="Pair Type") +
  scale_fill_manual(values = c("Within group"="lightgreen", "Between groups"="pink")) +
  theme_minimal()

#To report:

beta_results <- beta.multi(beta_core, index.family = "jaccard")
print(beta_results)

# Extract turnover values by pair type
within_turnover <- turnover_pairs$turnover[turnover_pairs$pair_type == "Within group"]
between_turnover <- turnover_pairs$turnover[turnover_pairs$pair_type == "Between groups"]

# Calculate means
mean_within <- mean(within_turnover)
mean_between <- mean(between_turnover)

# Calculate standard deviations
sd_within <- sd(within_turnover)
sd_between <- sd(between_turnover)

# Print results
mean_within; sd_within
mean_between; sd_between



## STATS

set.seed(123)  # for reproducibility

# Extract turnover values by pair type
within_turnover <- turnover_pairs$turnover[turnover_pairs$pair_type == "Within group"]
between_turnover <- turnover_pairs$turnover[turnover_pairs$pair_type == "Between groups"]

# Observed difference in means
obs_diff <- mean(between_turnover) - mean(within_turnover)

# Combine all turnover values and labels
all_values <- turnover_pairs$turnover
labels <- turnover_pairs$pair_type

# Permutation test
n_perm <- 999
perm_diffs <- numeric(n_perm)

for (i in 1:n_perm) {
  perm_labels <- sample(labels)  # shuffle labels
  perm_within <- all_values[perm_labels == "Within group"]
  perm_between <- all_values[perm_labels == "Between groups"]
  perm_diffs[i] <- mean(perm_between) - mean(perm_within)
}

# Calculate p-value (two-tailed)
p_value <- (sum(abs(perm_diffs) >= abs(obs_diff)) + 1) / (n_perm + 1)
p_value

ggplot(turnover_pairs, aes(x = pair_type, y = turnover, fill = pair_type)) +
  geom_boxplot() +
  labs(title = "Species Turnover Within and Between Groups",
       y = "Turnover (β_SIM)",
       x = "Pair Type") +
  scale_fill_manual(values = c("Within group" = "lightgreen", "Between groups" = "pink")) +
  theme_minimal() +
  annotate("text", x = 1.5, y = max(turnover_pairs$turnover) * 0.95, 
           label = paste0("p = ", signif(p_value, 3)), size = 5)

#Multipatt = Identify species that are characteristic of particular groups (here, east vs west). So e.g. "These taxa are diagnostic of Cluster X"

group_vector <- cluster_assignments$cluster[match(rownames(community_matrix), cluster_assignments$dive_name)]
indval <- multipatt(community_matrix, group_vector, func = "IndVal.g", control = how(nperm = 999))
summary(indval, indvalcomp = TRUE, alpha = 0.05)

#Meaning: 
#Species CAO11, CAO21, and PD03 are perfect indicators of cluster1. They only occur in that group (A = 1) and are always found there (B = 1).
# stat = 1 is the maximum possible IndVal. p.value < 0.05 means these are statistically significant indicator species.
# Same for cluster2 (east) with different species.
# Cluster 3 (deep site 5) represents a distinct community—it’s compositionally different enough that it doesn't share indicator species with the other clusters.
# It has low species turnover (i.e., species are widespread). It’s functionally or taxonomically unique but not strongly dominated by one taxon.
# Or it’s ecotonal (a transition zone between east/west clusters).

#The deep site doesnt work, because its only one location. But I can check separately, if there is any morphotype singularly occuring in the deep site. 

comm_pa <- community_matrix
comm_pa[comm_pa > 0] <- 1  # Convert to binary presence/absence

deep_site <- "EX2104_Dive05 Rockaway Seamount"
cluster1_sites <- rownames(comm_pa)[group_vector == "cluster1"]
cluster2_sites <- rownames(comm_pa)[group_vector == "cluster2"]

# Morphotypes present in the deep site
species_deep <- names(which(unlist(comm_pa[deep_site, ]) == 1))
species_deep
species_cluster1 <- names(which(colSums(comm_pa[cluster1_sites, ]) > 0))
species_cluster1
species_cluster2 <- names(which(colSums(comm_pa[cluster2_sites, ]) > 0))
species_cluster2

other_species <- names(which(colSums(comm_pa[c(cluster1_sites, cluster2_sites), ]) > 0))
# Unique to deep site
unique_to_deep <- setdiff(species_deep, other_species)
unique_to_deep 

#So now we can say that "CAH23" "CAO45" "PH69" "PH70" are only present in the deep site. Which we can maybe take as indicators? 


beta_results <- beta.multi(comm_pa, index.family = "sor")
beta_results

#Total beta diversity is high (β.SOR ≈ 0.83): There’s a lot of difference in species composition between your dives — which aligns with what you saw in the dbRDA.
#**Most of the variation is due to species turnover (β.SIM ≈ 0.79): Species are being replaced from one dive to another, rather than simply being lost or gained.
# Very little nestedness (β.SNE ≈ 0.037):This means communities are not just subsets of each other (e.g., Dive 5 isn’t just a "poorer" version of the east or west group). Instead, the communities have different species altogether.

```

> To complement this, we can do a SIMPER analysis (done by Ellen also in Primer, but jsut adding this here into the R script now). SIMPER identifies taxa that DISTINGUISH the groups. So its complementary to multipatt above. 

```{r}

#Simper = Identify species that contribute most to dissimilarity between groups.

# Run SIMPER
simper_results <- simper(community_matrix, group_vector, permutations = 999)
summary(simper_results, indvalcomp = TRUE, alpha = 0.05)


comparisons <- c("cluster1_cluster2", "cluster2_deep", "cluster1_deep")
simper.results <- c()
for(i in 1:length(comparisons)) {
temp <- summary(simper_results)[as.character(comparisons[i])] %>%
as.data.frame()
colnames(temp) <- gsub(
paste(comparisons[i],".", sep = ""), "", colnames(temp))
temp <- temp %>%
mutate(Comparison = comparisons[i],
Position = row_number()) %>%
  rownames_to_column(var = "Species")
simper.results <- rbind(simper.results, temp)
}

simper.results %>%
filter(p <= 0.05) %>%
select(Species, average, Comparison, Position)

p1 <- ggplot(data = simper.results,
aes(x = Position, y = cumsum)) +
geom_line(aes(colour = Comparison)) +
theme_bw()

p2 <- ggplot(data = simper.results,
aes(x = Position, y = average)) +
geom_line(aes(colour = Comparison)) +
theme_bw()

ggarrange(p1, p2, common.legend = TRUE)
#How to interpret: A straight diagonal line would indicate equal contributions by species. So in our case, it probably a few species that contribute the most. Also in p2 it gets obvious that over 50% of species are not contributing to the differences at all (the line is on 0). 

# Filter species with p <= 0.05 and position <= 10 (top 10 significant contributors)
top_simper <- simper.results %>%
  filter(p <= 0.05, Position <= 20)

# Check the filtered table
print(top_simper)

```


```{r}

#Visualize the results from above:

# Add cluster to your long-format species data
species_df <- community_matrix %>%
  as.data.frame() %>%
  rownames_to_column("dive_name") %>%
  left_join(cluster_assignments, by = "dive_name") %>%
  pivot_longer(-c(dive_name, cluster), names_to = "species", values_to = "abundance")

# Keep only indicator species - taken from results above
indicators <- c("CAO11", "CAO21", "PD03", "CAO29", "PD17", "CAO28")
species_df_filtered <- species_df %>%
  filter(species %in% indicators)

# Plot
ggplot(species_df_filtered, aes(x = species, y = abundance, fill = cluster)) +
  geom_bar(stat = "summary", fun = "mean", position = "dodge") +
  labs(title = "Indicator Species Abundance by Cluster", y = "Mean Abundance") +
  theme_minimal()

# Is geography or depth main reason? West locations are also deeper than in east

# Partial dbRDA: test depth effect controlling for geography (lat, lon)
partial_dbRDA_depth <- capscale(bray.df ~ depth + Condition(lat + lon), data = env2.z)
anova(partial_dbRDA_depth)  # test significance of depth after geography

# Partial dbRDA: test geography effect controlling for depth
partial_dbRDA_geo <- capscale(bray.df ~ lat + lon + Condition(depth), data = env2.z)
anova(partial_dbRDA_geo)  # test significance of geography after depth

#Meaning:
#Depth effect (controlling for lat/lon)	p = 0.23 (not significant)	Depth alone does not explain a significant part of community variation after accounting for geography.
#Geography effect (controlling for depth)	p = 0.125 (not significant)	Geography (lat + lon) also does not explain a significant part after accounting for depth.

# Assuming env.data.z has depth, lat, lon
var_part <- varpart(bray.df, ~ depth, ~ lat + lon, data = env2.z)
plot(var_part)
print(var_part)

#Results:
#Depth alone (after accounting for geography): ~4.65%
#Geography alone (after accounting for depth): ~9.82%
#Shared effect of depth & geography (overlap): ~5.37%
#Residuals (unexplained variation): ~80.16%

# Test unique effect of depth (a)
depth_only <- dbrda(bray.df ~ depth + Condition(lat + lon), data = env2.z)
anova(depth_only)

# Test unique effect of geography (b)
geo_only <- dbrda(bray.df ~ lat + lon + Condition(depth), data = env2.z)
anova(geo_only)

# Test combined effect (a+b+c)
full_model <- dbrda(bray.df ~ depth + lat + lon, data = env2.z)
anova(full_model)


```

# COMMUNITY COMPOSITION

## PcOA 

```{r, error = TRUE}

pcoa.bray <- cmdscale(bray.df, k = 2, eig = T)
# print(pcoa.bray) #explore output if wanted

# extract axis positions for each site from cmdscale object and create a dataframe for plotting
pcoa.bray.plotting <- as.data.frame(pcoa.bray$points)
colnames(pcoa.bray.plotting) <- c("pcoa1", "pcoa2")

# Create alpha diversity dataframe, include info about environment and locations
pcoa.bray.plotting <- cbind(pcoa.bray.plotting, ENV2)

# calculate the proportion of variance in the data which is explained by the first two PCoA axes
pcoa.bray$eig[1]/(sum(pcoa.bray$eig))
pcoa.bray$eig[2]/(sum(pcoa.bray$eig))

pcoa.bray.plotting$site <- data.c$dive_name
#pcoa.bray.plotting$watermass <- data.c$watermass

ggplot(pcoa.bray.plotting, aes(x = pcoa1, y = pcoa2, label=site, color=site)) +
  geom_point(size = 4) +
  #scale_shape_manual(values = c(15, 16, 17, 18, 19))+ 
  #ggtitle("PCA of Bray Curtis Dissimilarities") +
  geom_text_repel(min.segment.length = 0, size=4, box.padding = 1) +
  labs(col = "Site",
       x = "PCoA1",
       y = "PCoA2", 
       size = 5) +
  theme_linedraw() +
  # Confidence ellipses
  # stat_ellipse(aes(col = current), level = 0.95, linetype = "dashed") +
  theme(panel.grid = element_blank(),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        axis.title.x = element_text (size = 14),
        axis.title.y = element_text(size = 14),
        legend.background = element_blank(),
        legend.box.background= element_rect(colour="black"),
        legend.position = "right")


# Test the significance of factors on the distances
# TEST: Adonis2/PERMANOVA. Multivariate test for distance matrix as bray curtis e.g. 
variables <- c("depth", "medium","lon","lat")
results <- lapply(variables, function(var) adonis2(as.formula(paste("bray.df ~", var)), data = data.c))
results

# Extract key stats from each adonis2 result
results_summary <- lapply(results, function(res) {
  data.frame(
    R2 = res$R2[1],
    F = res$F[1],
    p_value = res$`Pr(>F)`[1]
  )
}) %>% 
  bind_rows() %>%
  mutate(variable = variables)

# Reorder columns for clarity
results_summary <- results_summary %>% select(variable, everything())
print(results_summary)

```

## Cluster analysis

> Morphotype clustering 

> The cluster analysis is an exploratory data analysis, and can be used to group a set of data into clusters. First, I am exploring the species data (morphotype-level) to assess clustering patterns among different morphotypes per site. The dissimilarity between morphotypes is computed using different clustering methods to find the best fit. I am using the site grouped dataset (SPE2) because I want to see which sites share similar morphotype compositions. 

```{r}

# First: Species data clustering
# Used Borcard's suggestion to explore the species data 

# Set seed for reproducibility
set.seed(123)

# Compute matrix of chord distance among morphotypes
spe.ch <- as.matrix(vegdist(SPE2.hel, "euc")) 
rownames(spe.ch) <- rownames(SPE2.hel)  # Ensure meaningful labels if available
colnames(spe.ch) <- rownames(SPE2.hel) 
spe.ch <- as.dist(spe.ch)

# Compute different hierarchical clustering methods
spe.ch.single <- hclust(spe.ch, method = "single")
spe.ch.complete <- hclust(spe.ch, method = "complete")
spe.ch.UPGMA <- hclust(spe.ch, method = "average") # UPGMA (best cophenetic correlation)
spe.ch.ward <- hclust(spe.ch, method = "ward.D2")

# Plot dendrograms
par(mfrow = c(2,2))  # Arrange plots in a grid
plot(spe.ch.single, main = "Chord - Single linkage", cex = 0.8)
plot(spe.ch.complete, main = "Chord - Complete linkage", cex = 0.8)
plot(spe.ch.UPGMA, main = "Chord - UPGMA", cex = 0.8)
plot(spe.ch.ward, main = "Chord - Ward", cex = 0.8)
par(mfrow = c(1,1))  # Reset plot layout

# Compute cophenetic correlation coefficients to evaluate clustering methods
spe.ch.single.coph <- cophenetic(spe.ch.single)
spe.ch.comp.coph <- cophenetic(spe.ch.complete)
spe.ch.UPGMA.coph <- cophenetic(spe.ch.UPGMA)
spe.ch.ward.coph <- cophenetic(spe.ch.ward)

# Print correlation values
cor(spe.ch, spe.ch.single.coph)  # Single Linkage
cor(spe.ch, spe.ch.comp.coph)  # Complete Linkage
cor(spe.ch, spe.ch.UPGMA.coph)  # UPGMA (expected highest)
cor(spe.ch, spe.ch.ward.coph)  # Ward's

# Highest correlation found in the UPGMA clustering with 0.88

# Cluster validation using bootstrap resampling
spech.pv <- pvclust(t(SPE2.hel), method.hclust = "average", method.dist = "euc", parallel = FALSE)
plot(spech.pv)

# Highlight clusters with high AU p-values (≥0.95 = significant)
pvrect(spech.pv, alpha = 0.95, pv = "au")

# Alternative: Determine optimal number of clusters using silhouette method
# Define a range of k values to test
k_values <- 2:8
sil_widths <- numeric(length(k_values))

# Compute silhouette width for each k
for (i in seq_along(k_values)) {
  cluster_assignments <- cutree(spe.ch.UPGMA, k = k_values[i])  # Get cluster labels
  sil <- silhouette(cluster_assignments, spe.ch)  # Compute silhouette scores
  sil_widths[i] <- mean(sil[, 3])  # Store average silhouette width
}

# Plot silhouette width vs. number of clusters
plot(k_values, sil_widths, type = "b", pch = 19, frame = FALSE,
     xlab = "Number of Clusters (k)", ylab = "Average Silhouette Width",
     main = "Optimal Cluster Selection via Silhouette Width")
abline(v = k_values[which.max(sil_widths)], col = "red", lty = 2)  # Mark optimal k

cluster_membership <- cutree(spe.ch.UPGMA, k = 3)
table(cluster_membership)

# Final reordered dendrogram with chosen clusters
# Convert to dendrogram and reorder it
dend <- as.dendrogram(spe.ch.UPGMA)
dend_reordered <- reorder(dend, spe.ch)
plot(dend_reordered, hang = 0, xlab = "Cluster Groups", ylab = "Height", main = "Chord - UPGMA (Reordered)")
rect.hclust(as.hclust(dend_reordered), k = 3)  # add cluster boxes

#Rows are dive IDs - 

```
> Environmental clustering 

> Continuing with environmental data. Which sites share cluster together that share similar environmental conditions? Does this correspond to geography? How does it relate to the species clusters? 

```{r}

# Environmental data clustering analysis
# Ensure NA rows are removed for environmental data

# Compute the distance matrix using Euclidean distance
env.ch <-as.matrix(vegdist(na.omit(env2.z), "euc")) # Attach site names to object of class 'dist'
rownames(env.ch) <- c("03","04", "05" , "06", "07" ,"08", "09", "10", "11") 
colnames(env.ch) <- c("03","04", "05" , "06", "07" ,"08", "09", "10", "11") 
env.ch <- as.dist(env.ch)

# Compute agglomerative clustering methods
env.ch.single <- hclust(env.ch, method = "single")
env.ch.complete <- hclust(env.ch, method = "complete")
env.ch.UPGMA <- hclust(env.ch, method = "average")  # UPGMA
env.ch.ward <- hclust(env.ch, method = "ward.D2")

# Plot dendrograms for different methods
par(mfrow = c(2, 2))  # Arrange plots in a grid
plot(env.ch.single, main = "Chord - Single linkage")
plot(env.ch.complete, main = "Chord - Complete linkage")
plot(env.ch.UPGMA, main = "Chord - UPGMA")
plot(env.ch.ward, main = "Chord - Ward")
par(mfrow = c(1, 1))  # Reset plot layout

# Compute cophenetic correlations to assess clustering method
env.ch.single.coph <- cophenetic(env.ch.single)
env.ch.comp.coph <- cophenetic(env.ch.complete)
env.ch.UPGMA.coph <- cophenetic(env.ch.UPGMA)
env.ch.ward.coph <- cophenetic(env.ch.ward)

# Print correlation values for each method
cor(env.ch, env.ch.single.coph)  # Single Linkage
cor(env.ch, env.ch.comp.coph)    # Complete Linkage
cor(env.ch, env.ch.UPGMA.coph)   # UPGMA (highest correlation)
cor(env.ch, env.ch.ward.coph)    # Ward's - Actually shows the zonation of east/west... 

# Perform p-value bootstrapping to validate clusters (approximate unbiased p-values)
envch.pv <- pvclust(t(env2.z), method.hclust = "average", method.dist = "eucl", parallel = TRUE)
plot(envch.pv)
pvrect(envch.pv, alpha = 0.95, pv = "au")  # Highlight significant clusters (AU p-value ≥ 0.95)

# Reorder the dendrogram
env.chwo <- reorder(env.ch.UPGMA, env.ch)

# Plot the reordered dendrogram
plot(env.chwo, hang = 0, xlab = "3 groups", ylab = "Height", main = "Chord - UPGMA (Reordered)")
rect.hclust(env.chwo, k = 3)  # Highlight 3 clusters

```

## Explorative PCA

```{r}

# PCA on Hellinger-transformed species data (SPE.hel)
spe.pca <- prcomp(SPE.hel, scale = TRUE)  # You can scale if needed
# PCA plot for species data
biplot(spe.pca, main = "PCA of Species Data") # You can adjust the biplot options to visualize axes and vectors better
#screeplot(spe.pca) 

# PCA on Environmental Data (env.z standardized)
env.pca <- prcomp(env.z, scale = TRUE) # exclude the previously added site and water mass and feature columns (not needed here anyways) 
biplot(env.pca, main = "PCA of Environmental Data") # Similar to species PCA, biplot shows the principal components
#screeplot(env.pca)

#Different approach 
pca_result <- PCA(bray.df, graph = FALSE)

# Create a data frame for plotting
pca_data <- data.frame(pca_result$ind$coord)
pca_data$dive_name <- rownames(pca_data)

# Create diversity dataframe, include info about environmnent and locations
pca_data <- cbind(pca_data, env2.z)

ggplot(pca_data, aes(x = Dim.1, y = Dim.2, color = depth)) +
  geom_point(size = 3) +
  scale_shape_manual(values = c(15, 16, 17, 18, 19, 20, 21, 22, 23))+ 
  ggtitle("PCA of Morphotype Diversity by Location") +
  theme_minimal() +
  theme(legend.position = "right")


```
> Procustes Analysis

> Procrustes analysis tests whether the species composition (PCA on species data) and environmental variables (PCA on environmental data) are significantly correlated. If they are, it suggests that the species distributions are likely influenced by the environmental gradients in your dataset. A significant correlation means that the patterns in species composition are in some way "shaped" by the environmental factors, making CCA a suitable next step.

```{r, warning=FALSE, error = TRUE}

# 2. Perform Procrustes Analysis
#Test significance  
env.Procrustes.sign <- protest(env.pca, spe.pca, scores="sites") 
env.Procrustes.sign

```
> Procrustes shows no high correlation between species and env data. R = 0.13, but slighlty. So we can proceed with NMDS, RDA - but there are probably other factors at play that explain the the clustering better than the used environmnetal characters....But since we see the clustering in the ordination analysis, this still gives a good hint. 

## NMDS

``` {r}

##NMDS

# 2. Run NMDS (k = 2 dimensions)
set.seed(123)
# FOR NOW USING DF1 - which has abundances NOT 0/1!!
nmds <- metaMDS(bray.df, k = 2, trymax = 100)

# 3. Extract NMDS site‐scores
nmds_scores <- as.data.frame(scores(nmds, display = "sites"))
nmds_scores$dive_name <- rownames(nmds_scores)

# Prepare NMDS site coordinates matrix
nmds_mat <- nmds_scores %>%
  select(NMDS1, NMDS2) %>%
  as.matrix()

# Run k-means
set.seed(123)
km_nmds <- kmeans(nmds_mat, centers = 3, nstart = 25)

cluster_assignments <- data.frame(
  dive_name = rownames(nmds_scores),
  cluster = factor(km_nmds$cluster)
)

nmds_df <- nmds_scores %>%
  left_join(cluster_assignments, by = "dive_name")

# 5. Plot NMDS
ggplot(nmds_df, aes(x = NMDS1, y = NMDS2, color = cluster, fill = cluster)) +
  geom_point(size = 3) +
  geom_text_repel(aes(label = dive_name), size = 3, box.padding = 0.4) +
  labs(
    title = "NMDS of Coral/Sponge Community (Bray–Curtis)",
    subtitle = paste0("Stress = ", round(nmds$stress, 3))
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom")

```

## dbRDA
> Next: Distance-Based Redundancy Analysis (dbRDA) - dbRDA can be used for non euclidian distances, such as Bray curtis 

```{r}

#dbRDA

# 1) Construct full model if needed, but now I am only interested in depth/lon/lat anyways... 

# 2) Run dbRDA (capscale) constraining on depth + lat + lon
dbRDA.mod <- capscale(bray.df ~ depth + lat + lon, data = env2.z)

# Check VIFs
vif_vals <- vif.cca(dbRDA.mod)
print(vif_vals)    # make sure no VIF is > 5 (or other chosen threshold)

# Permutation test for overall model (optional)
anova_all <- anova(dbRDA.mod, permutations = 999)
anova_terms <- anova(dbRDA.mod, by = "terms", permutations = 999)
print(anova_all)
print(anova_terms)

smry <- summary(dbRDA.mod)
smry
plot(dbRDA.mod)

# Extract site scores (CAP axes) and biplot scores for arrows
# Site scores (samples/dives) for CAP1 & CAP2
site_scores <- as.data.frame(smry$sites[, 1:2])
colnames(site_scores) <- c("CAP1", "CAP2")
site_scores$dive_name <- rownames(site_scores)

# Biplot (environmental vector) scores for arrow plotting
biplot_scores <- as.data.frame(smry$biplot[, 1:2])
colnames(biplot_scores) <- c("CAP1", "CAP2")
biplot_scores$variable <- rownames(biplot_scores)

# Plot the dbRDA in ggplot2
# Pull % variance explained for axis labels
# Extract proportion of variance explained by CAP1 and CAP2
rda_var <- summary(dbRDA.mod)$cont$importance["Proportion Explained", ]
rda1_pct <- round(rda_var[1] * 100, 2)  # dbRDA1
rda2_pct <- round(rda_var[2] * 100, 2)  # dbRDA2

# A. Extract the coordinates for clustering
scores_mat <- site_scores %>%
  select(CAP1, CAP2) %>%
  as.matrix()

# B. Run k-means clustering (adjust centers as needed)
set.seed(123)  # for reproducibility
km <- kmeans(scores_mat, centers = 3, nstart = 25)

# Convert to named cluster labels
site_scores <- site_scores %>%
  mutate(cluster = factor(km$cluster,
                          labels = c("deep", "cluster1", "cluster2")))

ggplot(site_scores, aes(x = CAP1, y = CAP2, color = cluster, fill = cluster)) +
  
  # (a) Make hulls by cluster
 geom_mark_hull(
  data = site_scores %>% group_by(cluster) %>% filter(n() > 1) %>% ungroup(),
  aes(x = CAP1, y = CAP2, group = cluster, fill = cluster),
  alpha = 0.1, 
  expand = unit(2, "mm"), 
  show.legend = FALSE
  ) + 
  
  # (b) Biplot arrows (disable inheriting color/cluster from the global aes)
  geom_segment(
    data = biplot_scores,
    aes(x = 0, xend = CAP1, y = 0, yend = CAP2),
    inherit.aes = FALSE, 
    arrow = arrow(length = unit(0.015, "npc")),
    color = "grey50"
  ) +
  
  # (c) Arrow labels (again, no cluster mapping here)
  geom_text_repel(
    data = biplot_scores,
    aes(x = CAP1, y = CAP2, label = variable),
    inherit.aes = FALSE,
    color = "grey50",
    size = 3,
    box.padding = 0.3
  ) +
  
  # (d) Points for each dive (inherits color = cluster)
  geom_point(size = 3) +
  
  # (e) Dive labels (inherits nothing extra, just label from site_scores)
  geom_text_repel(
    aes(label = dive_name),
    size = 3,
    min.segment.length = 0,
    box.padding = 0.4,
    show.legend = FALSE
  ) +
  
  # (f) Zero lines (no cluster mapping)
  geom_hline(yintercept = 0, linetype = "dotted", inherit.aes = FALSE) +
  geom_vline(xintercept = 0, linetype = "dotted", inherit.aes = FALSE) +
  
  # (g) Axis limits and fixed ratio
  coord_fixed(ratio = 1) +
  xlim(-2, 2) +
  ylim(-2, 2) +
  
  # (h) Axis labels (add your % variance)
  xlab(paste0("dbRDA1 (", rda1_pct, "%)")) +
  ylab(paste0("dbRDA2 (", rda2_pct, "%)"))+
  
  # (i) Color/fill scales for cluster
  scale_color_manual(
    values = c("cluster1" = "#1B9E77",
               "cluster2" = "#D95F02",
               "deep"     = "#7570B3"),
    name = "Cluster"
  ) +
  scale_fill_manual(
    values = c("cluster1" = "#1B9E77",
               "cluster2" = "#D95F02",
               "deep"     = "#7570B3"),
    name = "Cluster"
  ) +
  
  # (j) Theme adjustments
  theme_bw(base_size = 14) +
  theme(
    legend.position = "bottom",
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey90"),
    panel.grid.major.y = element_blank()
  )

```

# FOREST ANALYSIS

## Densities 

> I put this in the same df as the length data, but as sheets. Now I saved each individual sheet as a file, to be able to work with it. 
All files are availabe from the Supplementary File (just save each sheet separately)

```{r}

# Read all garden files
# You may need to adapt the path

file_paths <- c(
  "./garden_densities/D04_GA.xlsx", 
  "./garden_densities/D04_GB.xlsx", 
  "./garden_densities/D07_GA.xlsx", 
  "./garden_densities/D08_GA.xlsx", 
  "./garden_densities/D08_GB.xlsx", 
  "./garden_densities/D11_GA.xlsx"
)


# Read each file into a list of data frames
list_of_dfs <- lapply(file_paths, read_excel)

# Optionally add a garden_id column from the filename for each df
garden_ids <- c("D04_GA", "D04_GB", "D07_GA", "D08_GA", "D08_GB", "D11_GA")
list_of_dfs <- Map(function(df, id) {
  df$garden_id <- id
  return(df)
}, list_of_dfs, garden_ids)

processed_list <- lapply(list_of_dfs, function(df) {
  df %>%
    # Summarize counts per frame_no and morphotype (in case of duplicates)
    group_by(garden_id, frame_no, frame_time, area_square, morphotype) %>%
    summarise(count = sum(count, na.rm = TRUE), .groups = "drop") %>%
    # Pivot morphotypes wider as columns
    pivot_wider(names_from = morphotype, values_from = count, values_fill = 0) %>%
    # Calculate total individuals
    mutate(total_ind = rowSums(across(where(is.numeric) & !c(area_square)), na.rm = TRUE)) %>%
    # Calculate densities
    mutate(
      density_per_m_squared = total_ind / area_square,
      density_per_10m_squared = density_per_m_squared * 10
    ) %>%
    # Optional: add frame_id
    mutate(frame_id = paste(garden_id, frame_no, sep = "_")) %>%
    select(garden_id, frame_id, frame_no, frame_time, area_square, everything())
})


# Function to calculate average density per morphotype
summarize_density_df <- function(df) {
  df %>%
    group_by(garden_id) %>%
    summarise(across(starts_with("P") | starts_with("C"), ~ mean(.x / area_square, na.rm = TRUE))) %>%
    pivot_longer(cols = -garden_id, names_to = "Morphotype", values_to = "density")
}

# Apply function to all garden data
gardens_df <- bind_rows(lapply(processed_list, summarize_density_df), .id = "df_id")

# Join with taxa data (assumed to be available)
gardens_df <- gardens_df %>%
  left_join(taxa, by = "Morphotype")

# Plot function to simplify repeated plot code
plot_density <- function(data, group_col, fill_col, title) {
  data %>%
    group_by(garden_id, !!sym(group_col)) %>%
    summarise(total_density = sum(density)) %>%
    mutate(prop_density = total_density / sum(total_density)) %>%
    ggplot(aes(x = garden_id, y = total_density, fill = !!sym(group_col))) +
    geom_bar(stat = "identity", aes(weight = prop_density), position = "stack") +
    labs(x = "Garden ID", y = "Individuals per m^2", title = title) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

# Plot densities by Phylum, Morphotype, and Family
plot_density(gardens_df, "Phylum", "Phylum", "Densities by Phylum")
plot_density(gardens_df, "Morphotype", "Morphotype", "Densities by Morphotype")
plot_density(gardens_df, "Family", "Family", "Densities by Family")

# Calculate sponge-dominated gardens
sponge_dominated <- gardens_df %>%
  group_by(garden_id, Phylum) %>%
  summarise(total_density = sum(density, na.rm = TRUE)) %>%
  group_by(garden_id) %>%
  mutate(proportion = total_density / sum(total_density, na.rm = TRUE)) %>%
  filter(Phylum == "Porifera") %>%
  mutate(is_sponge_dominated = proportion >= 0.7)

# Output results
kable(sponge_dominated) %>% kable_styling(font_size = 7, latex_options = c("striped"))

# Calculate coral-dominated gardens
coral_dominated <- gardens_df %>%
  group_by(garden_id, Phylum) %>%
  summarise(total_density = sum(density, na.rm = TRUE)) %>%
  group_by(garden_id) %>%
  mutate(proportion = total_density / sum(total_density, na.rm = TRUE)) %>%
  filter(Phylum == "Cnidaria") %>%
  mutate(is_coral_dominated = proportion >= 0.7)

# Output results
kable(coral_dominated) %>% kable_styling(font_size = 7, latex_options = c("striped"))

```

> Now do some analysis and plotting of forest data. Bubble plots to show local densitites and dive tracks to get better overview.

```{r}

# Step 1: Combine all processed garden frame tables
garden_long <- processed_list %>%
  bind_rows() %>%
  pivot_longer(
    cols = -c(garden_id, frame_id, frame_no, frame_time, area_square, total_ind, density_per_m_squared, density_per_10m_squared),
    names_to = "morphotype",
    values_to = "count"
  ) %>%
  filter(count > 0)

garden_long <- garden_long %>%
  mutate(
    expedition = "EX2104",
    dive_number = stringr::str_extract(garden_id, "\\d+"),
    garden = stringr::str_remove(garden_id, "D0*\\d+_"),  # GA/GB becomes garden
    garden = paste0(dive_number, stringr::str_replace(garden, "G", "")),  # 4A, 4B...
    frame_no = stringr::str_extract(frame_id, "\\d+$")
  )


# Ensure datetime format
garden_long$frame_time <- as.POSIXct(garden_long$frame_time)
data.a$time <- as.POSIXct(data.a$time)


garden_long <- garden_long %>%
  rowwise() %>%
  mutate(
    closest_row = list(
      data.a %>%
        mutate(time_diff = abs(as.numeric(difftime(time, frame_time, units = "secs")))) %>%
        filter(time_diff == min(time_diff, na.rm = TRUE)) %>%
        slice(1)
    )
  ) %>%
  unnest(cols = c(closest_row), names_sep = ".matched_") %>%
  ungroup()


# Identify all current column names
current_names <- names(garden_long)
# Find columns with the prefix
matched_cols <- grep("^closest_row\\.matched_", current_names, value = TRUE)
# Compute the cleaned names
cleaned_names <- gsub("^closest_row\\.matched_", "", matched_cols)
# Keep only those where the cleaned name does NOT already exist
safe_renames <- matched_cols[!cleaned_names %in% current_names]

# Apply safe renaming
garden_long <- garden_long %>%
  rename_with(
    .cols = all_of(safe_renames),
    .fn = ~ gsub("^closest_row\\.matched_", "", .x)
  )


garden_long <- garden_long %>%
  mutate(
    garden = case_when(
      grepl("^08", garden) ~ garden,            # Keep all "08" gardens separate
      TRUE ~ sub("([0-9]{2})[AB]$", "\\1", garden)  # Remove trailing A or B from others like "04A" -> "04"
    )
  )


garden_summary <- garden_long %>%
  group_by(garden_id) %>%
  summarise(
    n_frames = n_distinct(frame_id),
    mean_density = mean(density_per_m_squared),
    sd_density = sd(density_per_m_squared),
    total_individuals = sum(count),
    richness = n_distinct(morphotype)
  )
garden_summary


garden_frame_density <- garden_long %>%
  distinct(garden_id, frame_id, density_per_m_squared)

# Kruskal-Wallis test (non-parametric ANOVA)
kruskal.test(density_per_m_squared ~ garden_id, data = garden_frame_density)

ggplot(garden_frame_density, aes(x = garden_id, y = density_per_m_squared)) +
  geom_boxplot() +
  theme_minimal() +
  ylab("Density (ind/m²)")

```
## Forest vs non-forest

```{r}

# I can't compare non-garden vs garden densities because of lacking area data for non garden. 
# BUT I can look at the diversity (are gardens more diverse?) OR are the compositions inside the garden different? 

#1) DIVERSITY Garden vs non-garden
# OBS: There will be a bias, because gardens have much less frames compared to non gardens obviously. 

# Step 1: Sum counts per morphotype for each garden
garden_community <- garden_long %>%
  group_by(garden_id, morphotype) %>%
  summarise(count = sum(count), .groups = "drop") %>%
  pivot_wider(names_from = morphotype, values_from = count, values_fill = 0)

# Step 2: Save garden IDs
garden_ids <- garden_community$garden_id

# Step 3: Remove garden_id for diversity calculation
community_matrix <- garden_community %>% select(-garden_id)

# Step 4: Calculate Shannon diversity for each garden
H_garden <- diversity(community_matrix, index = "shannon")

# Step 5: Combine results into a tidy dataframe
shannon_garden <- data.frame(
  garden_id = garden_ids,
  H = H_garden
)


# Convert the named vector `H` to a dataframe
H_dive <- data.frame(
  dive_name = names(H),
  H = as.numeric(H),
  source = "non-garden"
)

shannon_garden <- shannon_garden %>%
  mutate(dive_name = case_when(
    garden_id %in% c("D04_GA", "D04_GB") ~ "EX2104_Dive04",
    garden_id == "D07_GA"               ~ "EX2104_Dive07",
    garden_id %in% c("D08_GA", "D08_GB") ~ "EX2104_Dive08",
    garden_id == "D11_GA"               ~ "EX2104_Dive11"
  ),
  source = "garden")

H_combined <- bind_rows(
  shannon_garden %>% select(dive_name, H, source),
  H_dive
)

ggplot(H_combined, aes(x = source, y = H)) +
  geom_boxplot(fill = "lightblue") +
  geom_jitter(width = 0.1, size = 2, alpha = 0.6) +
  theme_minimal() +
  labs(y = "Shannon diversity (H)", x = "Zone")

wilcox.test(H ~ source, data = H_combined)

H_combined <- H_combined %>%
  mutate(
    dive_name_clean = if_else(
      source == "non-garden",
      str_extract(dive_name, "^[^ ]+"),  # Extract substring before first space
      dive_name
    )
  )

# Filter only those dives with garden data - Before I included ALL dive locations, which is also interesting, but not necessarily relevant. 
dives_with_garden <- unique(H_combined$dive_name_clean[H_combined$source == "garden"])

H_filtered <- H_combined %>%
  filter(dive_name_clean %in% dives_with_garden)

# Summarize mean H per dive and source
H_wide <- H_filtered %>%
  group_by(dive_name_clean, source) %>%
  summarise(H_mean = mean(H), .groups = "drop") %>%
  pivot_wider(names_from = source, values_from = H_mean) %>%
  drop_na()

#Paired and unpaired test:
wilcox.test(H_wide$garden, H_wide$`non-garden`, paired = TRUE) # So within each dive, the H is not different significantly. 
wilcox.test(H_wide$garden, H_wide$`non-garden`, paired = FALSE) # But when looking at all the garden/non garden sites independently, then yes - the gardens are less diverse than the non gardens. 

plot_data <- H_filtered %>%
  select(dive_name_clean, source, H) %>%
  rename(Dive = dive_name_clean, Source = source, Shannon_H = H)

# Optional: order dives by mean Shannon H to make plot clearer
plot_data <- plot_data %>%
  group_by(Dive) %>%
  mutate(mean_H = mean(Shannon_H)) %>%
  ungroup() %>%
  arrange(mean_H) %>%
  mutate(Dive = factor(Dive, levels = unique(Dive)))

# Plot paired points connected by lines
ggplot(plot_data, aes(x = Source, y = Shannon_H, group = Dive, color = Dive)) +
  geom_point(size = 3) +
  geom_line(alpha = 0.5) +
  theme_minimal() +
  labs(title = "Comparison of Shannon Diversity (H) between Garden and Non-Garden Areas",
       x = "Area Type",
       y = "Shannon Diversity Index (H)") +
  theme(legend.position = "none")

```
> The next stats are not very relevant, because Permanova needs more than 2 sites to compare, but I only have 1 garden by dive site (or 2). So ignore.

```{r}

#2) Compositions 
# Test if the compositions are different between garden and non-garden areas.
# I will only use the selected garden dive locations, ignore the rest of the dive locations. 

# 1. Prepare garden community matrix (example: counts per garden_id and morphotype)
garden_comm <- garden_long %>%
  group_by(garden_id, morphotype) %>%
  summarise(total_count = sum(count, na.rm = TRUE)) %>%
  pivot_wider(names_from = morphotype, values_from = total_count, values_fill = 0) %>%
  ungroup()

# Make garden sample names rownames
garden_mat <- garden_comm %>%
  column_to_rownames("garden_id")

# 2. Prepare non-garden community matrix

# Ensure same columns (species) in both
all_species <- union(colnames(garden_mat), colnames(data.c[,2:113]))

# Add missing species columns filled with zeros
add_missing_cols <- function(mat, species) {
  missing <- setdiff(species, colnames(mat))
  if(length(missing) > 0){
    mat[, missing] <- 0
  }
  # Reorder columns
  mat <- mat[, species]
  return(mat)
}

garden_mat <- add_missing_cols(garden_mat, all_species)

# Check column names
all(colnames(SPE.pa) == colnames(garden_mat))  # should be TRUE

# If FALSE, reorder columns in garden_mat to match SPE.pa
garden_mat <- garden_mat[, colnames(SPE.pa)]
SPE.pa_df <- as.data.frame.matrix(SPE.pa)

# Vector of full row names to remove
rows_to_remove <- c(
  "EX2104_Dive03 Hopscotch Seamount",
  "EX2104_Dive05 Rockaway Seamount",
  "EX2104_Dive06 Castle Rock Seamount",
  "EX2104_Dive09 Yakutat Shallow Seamount",
  "EX2104_Dive10 Yakutat Deep Seamount"
)

# Subset SPE.pa_df excluding those rows
SPE.pa_df <- SPE.pa_df[!rownames(SPE.pa_df) %in% rows_to_remove, ]

# Check remaining rows
rownames(SPE.pa_df)

combined_mat <- rbind(garden_mat, SPE.pa_df)

# 4. Calculate Bray-Curtis dissimilarity
bray_combined <- vegdist(combined_mat, method = "bray")

# Step 1: Make sure your grouping vector matches the rows of the dissimilarity matrix
group_vector <- c(
  rep("garden", 6),  # first 6 rows = garden IDs
  rep("non-garden", nrow(bray_combined) - 6)
)

# Step 2: Run PERMANOVA
adonis_result <- adonis2(as.dist(bray_combined) ~ group_vector)
print(adonis_result) #This compares ALL gardens to the non garden sites. No pairing here. 

# Now compare biological community dissimilarities between garden replicates and their corresponding non-garden dive sites

# List of garden-to-dive mappings
garden_to_dive <- list(
  "D04" = "EX2104_Dive04 Dumbbell Seamount",
  "D07" = "EX2104_Dive07 Corner Rise 1 Seamount",
  "D08" = "EX2104_Dive08 MacGregor Seamount",
  "D11" = "EX2104_Dive11 Caloosahatchee Seamount"
)

# Convert to a square matrix
bray_combined <- as.matrix(bray_combined)

# Extract garden IDs from the dissimilarity matrix
garden_ids <- rownames(bray_combined)[grepl("^D\\d{2}_G", rownames(bray_combined))]

# Extract unique prefixes to group gardens by site (e.g., D04)
garden_prefixes <- unique(sub("_G.*", "", garden_ids))

# Store results
adonis_results <- list()

for (prefix in garden_prefixes) {
  # Get corresponding garden rows (can be GA, GB, etc.)
  garden_rows <- grep(paste0("^", prefix, "_G"), rownames(bray_combined), value = TRUE)
  
  # Get matching dive name
  dive_name <- garden_to_dive[[prefix]]
  
  # Make sure dive exists in matrix
  if (!is.null(dive_name) && dive_name %in% rownames(bray_combined)) {
    
    # Combine garden and non-garden site
    subset_ids <- c(garden_rows, dive_name)
    
    # Subset dissimilarity matrix
    dist_subset <- as.dist(bray_combined[subset_ids, subset_ids])
    
    # Create metadata
    group <- c(rep("garden", length(garden_rows)), "non-garden")
    metadata <- data.frame(site = subset_ids, group = group)
    
    # Run PERMANOVA
    adonis_res <- adonis2(dist_subset ~ group, data = metadata, permutations = 999)
    
    # Store result
    adonis_results[[prefix]] <- adonis_res
  }
}

# Print all results
for (prefix in names(adonis_results)) {
  cat("-----", prefix, "-----\n")
  print(adonis_results[[prefix]])
  cat("\n")
}

# The sample size is too low for a robust analysis here. But can do a NMDS to explore the data at least: 

# Prepare distance matrix (if not already dist)
if (!inherits(bray_combined, "dist")) {
  bray_dist <- as.dist(bray_combined)
} else {
  bray_dist <- bray_combined
}

names(group_vector) <- rownames(bray_combined)
set.seed(42)
nmds <- metaMDS(bray_dist, k = 2, trymax = 100)

scores_df <- as.data.frame(scores(nmds))
scores_df$SampleID <- rownames(scores_df)
scores_df$Group <- group_vector[scores_df$SampleID]

ggplot(scores_df, aes(x = NMDS1, y = NMDS2, color = Group)) +
  geom_point(size = 3, alpha = 0.8) +
  ggrepel::geom_text_repel(aes(label = SampleID), size = 3) +
  stat_ellipse(level = 0.95) +
  theme_minimal() +
  labs(title = "NMDS: Garden vs Non-Garden Sites",
       x = "NMDS1", y = "NMDS2",
       color = "Site Group") +
  theme(text = element_text(size = 14))

```

> I want to plot the densitites across the forest area, showing porifera and corals and their densitities. 

## Plotting of forest transects

``` {r}

# Basic plot: density by lat/lon
ggplot(garden_long, aes(x = lon, y = lat)) +
  geom_point(aes(size = count, color = Phylum, shape = Phylum), alpha = 0.5) +
  scale_size_continuous(range = c(1,8)) +
  facet_wrap(~ garden, scales = "free") +
  labs(
    title = "Spatial Distribution of Individuals by Phylum",
    x = "Longitude", y = "Latitude",
    size = "Count", color = "Phylum", shape = "Phylum"
  ) +
  theme_minimal()

ggplot(garden_long, aes(x = lon, y = lat)) +
  geom_point(aes(size = count, color = Phylum, shape = Phylum), alpha = 0.5) +
  scale_size_continuous(range = c(1, 8)) +
  facet_wrap(~ garden, scales = "free") +
  labs(size = "Count", color = "Phylum", shape = "Phylum") +
  theme_minimal()

ggplot(garden_long, aes(x = lon, y = lat)) +
  geom_point(aes(size = count, color = Phylum, shape = Phylum), alpha = 0.5) +
  scale_size_continuous(range = c(0, 12)) +
  facet_wrap(~ garden, scales = "free") +
  coord_cartesian(expand = TRUE, clip = "off") +
  labs(size = "Count", color = "Phylum", shape = "Phylum") +
  theme_minimal()

#Add transect line to plots

garden_ranges <- garden_long %>%
  group_by(garden) %>%
  summarise(start_time = min(frame_time), end_time = max(frame_time), .groups = "drop")

# For each garden, extract the matching transect points
expanded_garden_paths <- purrr::map_dfr(unique(garden_long$garden), function(g) {
  range <- garden_ranges %>% filter(garden == g)
  data.a %>%
    filter(time >= range$start_time, time <= range$end_time) %>%
    mutate(garden = g)
})


ggplot(garden_long, aes(x = lon, y = lat)) +
  geom_path(data = expanded_garden_paths,
            aes(x = lon, y = lat, group = garden),
            color = "grey40", linewidth = 0.5, alpha = 0.2) +
  geom_point(aes(size = count, color = Phylum, shape = Phylum), alpha = 0.6) +
  scale_size_continuous(range = c(0, 12)) +
  facet_wrap(~ garden, scales = "free") +
  coord_cartesian(clip = "off") +
  labs(size = "Count", color = "Phylum", shape = "Phylum") +
  theme_minimal()


ggplot() +
  geom_smooth(data = expanded_garden_paths, 
              aes(x = lon, y = lat, group = garden), 
              method = "loess", span = 0.5, se = FALSE, color = "grey91", linewidth = 4) +
  geom_point(data = garden_long, 
             aes(x = lon, y = lat, size = count, color = Phylum, shape = Phylum),
             alpha = 0.6) +
  scale_size_continuous(range = c(1, 10)) +
  facet_wrap(~ garden, scales = "free") +
  theme_minimal()


```

## Forest sizes

``` {r}

library(sf)

# Using "expanded_garden_paths" from before
df <- expanded_garden_paths

# Function to compute seafloor area for one garden
compute_surface_area <- function(garden_df) {
  # --- Step 1: make polygon from lat/lon ---
  coords <- garden_df %>%
    select(lon, lat) %>%
    distinct() %>%
    as.matrix()
  
  # Close the polygon (last point = first point)
  if (!all(coords[1,] == coords[nrow(coords),])) {
    coords <- rbind(coords, coords[1,])
  }
  
  poly <- st_polygon(list(coords)) |> st_sfc(crs = 4326)
  
  # --- Step 2: project to local UTM ---
  lon_mean <- mean(garden_df$lon, na.rm = TRUE)
  utm_zone <- floor((lon_mean + 180)/6) + 1
  epsg <- 32600 + utm_zone  # WGS84 UTM Northern Hemisphere (fits to Corner Rise area)
  poly_m <- st_transform(poly, epsg)
  
  # --- Step 3: flat area ---
  area_flat <- as.numeric(st_area(poly_m))  # m^2
  
  # --- Step 4: fit plane to depth values ---
  pts <- st_as_sf(garden_df, coords = c("lon","lat"), crs = 4326)
  pts_m <- st_transform(pts, epsg)
  XY <- st_coordinates(pts_m)
  
  fit <- lm(depth ~ X + Y, data = data.frame(depth = garden_df$depth,
                                             X = XY[,1], Y = XY[,2]))
  
  bx <- coef(fit)["X"]
  by <- coef(fit)["Y"]
  
  slope_rad <- atan(sqrt(bx^2 + by^2))
  
  # --- Step 5: correct area ---
  area_surface <- area_flat / cos(slope_rad)
  
  tibble(
    dive_id = unique(garden_df$dive_id),
    flat_area_m2 = area_flat,
    slope_deg = slope_rad * 180/pi,
    surface_area_m2 = area_surface
  )
}

# Apply per garden (grouped by garden)
result <- df %>%
  group_by(garden) %>%
  group_modify(~ compute_surface_area(.x))

print(result)
#So most are above 25m2


```


## Forest communtities

``` {r}

# Garden communtities, find the dominant taxa:

#This selects the dominant taxa, all that make up over 25% of the total abundance per garden 
dominant_morphotypes_25 <- garden_community %>%
  pivot_longer(cols = -garden_id, names_to = "morphotype", values_to = "abundance") %>%
  group_by(garden_id) %>%
  mutate(
    total_abundance = sum(abundance),
    rel_abundance = abundance / total_abundance
  ) %>%
  filter(rel_abundance > 0.25) %>%   # Filter morphotypes with >30% of total
  arrange(garden_id, desc(rel_abundance)) %>%
  ungroup()

dominant_morphotypes_25

```

## Forest transect lengths

``` {r}

garden_ranges <- garden_long %>%
  group_by(garden_id) %>%
  summarise(
    start_time = first(frame_time),
    end_time = last(frame_time),
    .groups = "drop"
  )


# Function to calculate 3D segment distances for a garden
calculate_garden_track <- function(garden) {
  garden_data <- data.segmented %>%
    filter(time >= garden$start_time & time <= garden$end_time)

  if (nrow(garden_data) < 2) return(NULL)

  # Calculate 2D haversine distance
  dist2D <- distHaversine(
    cbind(garden_data$lon_smooth[-nrow(garden_data)], garden_data$lat_smooth[-nrow(garden_data)]),
    cbind(garden_data$lon_smooth[-1], garden_data$lat_smooth[-1])
  )

  # Vertical difference (depth)
  delta_depth <- diff(garden_data$depth)

  # 3D distance
  dist3D <- sqrt(dist2D^2 + delta_depth^2)

  tibble(
    garden_id = garden$garden_id,
    n_points = nrow(garden_data),
    track_length_3D_m = sum(dist3D, na.rm = TRUE),
    min_depth = min(garden_data$depth, na.rm = TRUE),
    max_depth = max(garden_data$depth, na.rm = TRUE),
    mean_depth = mean(garden_data$depth, na.rm = TRUE)
  )
}

# Apply to each garden
garden_track_summary <- garden_ranges %>%
  group_split(garden_id) %>%
  map_dfr(calculate_garden_track)

garden_track_summary

```


